{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DB Blog LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "roEyCY1b7TTw",
        "colab_type": "code",
        "outputId": "10b10e8e-e6d5-47f8-a2c1-3c46179fae30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I52OxyBgfi_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import spacy\n",
        "import string\n",
        "import pickle as pkl\n",
        "from sklearn import preprocessing\n",
        "import os.path\n",
        "from operator import add\n",
        "from collections import Counter\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "if os.getcwd() != '/content/drive/My Drive/NLU':\n",
        "  %cd 'drive/My Drive/NLU'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljQ3L-IB9O9W",
        "colab_type": "code",
        "outputId": "91671cc1-6ab1-493a-9cc6-d6681d6b9fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip install sacremoses\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "import sacremoses\n",
        "from torch.utils.data import dataloader, Dataset\n",
        "import tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (0.0.43)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.14.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "152LbKl79XGG",
        "colab_type": "code",
        "outputId": "58720040-606e-4e61-d5f5-1d861b326dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "blogs = pd.read_csv(\"blogtext.csv.zip\")\n",
        "blogs.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'gender', 'age', 'topic', 'sign', 'date', 'text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQPS1Rrd9YEW",
        "colab_type": "code",
        "outputId": "27a455bb-b73f-48ca-d9a6-631720ae65b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#creating labels, 1 is ages 13-17, 2 is ages 23-27, 3 is 33-47\n",
        "\n",
        "#first create a list of indicators for each age bracket \n",
        "def create_age_bracket(lower_bound, upper_bound):\n",
        "    under_upper = 1*(blogs['age'] <=upper_bound)\n",
        "    over_lower = 1*(blogs['age'] >=lower_bound)\n",
        "\n",
        "    return 1*((under_upper + over_lower) == 2)\n",
        "\n",
        "ones = create_age_bracket(13,17)\n",
        "twenties = create_age_bracket(23,27)\n",
        "thirties = create_age_bracket(33,47)\n",
        "\n",
        "print('there are', np.sum(ones), 'blog posts from people aged 13-17')\n",
        "print('there are', np.sum(twenties), 'blog posts from people aged 23-27')\n",
        "print('there are', np.sum(thirties), 'blog posts from people aged 33-47')\n",
        "\n",
        "#creating 'label' column by combining indicator lists\n",
        "blogs['label'] = ones + 2*twenties +3*thirties\n",
        "\n",
        "#removing instances that don't fit the age buckets\n",
        "blogs = blogs[blogs['label'] != 0]\n",
        "blogs.columns[6]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 235867 blog posts from people aged 13-17\n",
            "there are 321447 blog posts from people aged 23-27\n",
            "there are 120398 blog posts from people aged 33-47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'text'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_sfIgAY9eqv",
        "colab_type": "code",
        "outputId": "77620c0a-3fce-42c7-ee18-bebbd7b2b9b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#making training, validation, and test sets (70%,15%,15% split)\n",
        "np.random.seed(23)\n",
        "\n",
        "n = blogs.shape[0]\n",
        "train_size = int(n*.7)\n",
        "val_size = int(n*.15)\n",
        "test_size = n - train_size-val_size\n",
        "\n",
        "train_ids = np.random.choice(n, replace=False, size=train_size)\n",
        "test_val_ids = np.asarray(list((set(np.arange(n)) - set(train_ids))))\n",
        "val_ids = np.random.choice(a=test_val_ids, replace=False, size=val_size)\n",
        "test_ids = np.array(list(set(test_val_ids)-set(val_ids)))\n",
        "\n",
        "train_df = blogs.iloc[train_ids]\n",
        "val_df = blogs.iloc[val_ids]\n",
        "test_df = blogs.iloc[test_ids]\n",
        "\n",
        "print('size of training set:', train_df.shape[0])\n",
        "print('size of validation set:',val_df.shape[0])\n",
        "print('size of test set:', test_df.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of training set: 474398\n",
            "size of validation set: 101656\n",
            "size of test set: 101658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afxLG3fj9kWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the code cell that tokenizes train/val/test datasets\n",
        "\n",
        "# lowercase and remove punctuation\n",
        "def tokenize(sent):\n",
        "    tokens = tokenizer(sent)\n",
        "    return [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
        "\n",
        "def tokenize_dataset(dataset):\n",
        "    token_dataset = []\n",
        "    # we are keeping track of all tokens in dataset \n",
        "    # in order to create vocabulary later\n",
        "    all_tokens = []\n",
        "    \n",
        "    count = 0\n",
        "    for sample in dataset:\n",
        "        tokens = tokenize(sample)\n",
        "        token_dataset.append(tokens)\n",
        "        all_tokens += tokens\n",
        "\n",
        "        count += 1\n",
        "        if count%1000 == 0:\n",
        "          print(count)\n",
        "\n",
        "    return token_dataset, all_tokens\n",
        "\n",
        "tokenizer = spacy.load('en_core_web_sm')\n",
        "punctuations = string.punctuation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oTgw3_89tmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting training set into two in order to perform preproccessing\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "n = train_df.shape[0]\n",
        "chunk_size = int(n/4)\n",
        "\n",
        "chunks = {}\n",
        "chunks[1] = train_df['text'][0:chunk_size]\n",
        "chunks[2] = train_df['text'][chunk_size: 2*chunk_size]\n",
        "chunks[3] = train_df['text'][2*chunk_size: 3*chunk_size]\n",
        "chunks[4] = train_df['text'][3*chunk_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfOPYyTC9vDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving tokenized data as pickle files\n",
        "if not os.path.exists('val_tokens.p'):\n",
        "    print(\"Tokenizing validation data\")\n",
        "    val_tokens, _ = tokenize_dataset(val_df['text'])\n",
        "    pkl.dump(val_tokens, open(\"val_tokens.p\", \"wb\"))\n",
        "\n",
        "    print(\"Tokenizing test data\")\n",
        "    val_tokens, _ = tokenize_dataset(test_df['text'])\n",
        "    pkl.dump(val_tokens, open(\"test_tokens.p\", \"wb\"))\n",
        "\n",
        "if not os.path.exists('all_tokens_4.p'):\n",
        "    for i in range(4):\n",
        "        print(\"tokenizing chunk \" + str(i+1))\n",
        "        train_tokens, train_all_tokens = tokenize_dataset(chunks[i+1])\n",
        "        pkl.dump(train_tokens, open(\"train_tokens_\"+ str(i+1) +\".p\", \"wb\"))\n",
        "        pkl.dump(train_all_tokens, open(\"all_tokens_\" +str(i+1) +\".p\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT8rGvl_9-Lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAD_IDX = 0\n",
        "UNK_IDX = 1\n",
        "max_vocab_size = 10000\n",
        "\n",
        "#creating pickle files for id2token and token2id dictionaries\n",
        "if not os.path.exists('id2token.p'):\n",
        "    token_dct = {}\n",
        "    index_dct = {}\n",
        "    for i in range(4):\n",
        "        print(i)\n",
        "        all_tokens = pkl.load(open(\"all_tokens_\" + str(i+1) +\".p\", \"rb\"))\n",
        "        for token in all_tokens:\n",
        "            if token in token_dct.keys():\n",
        "                token_dct[token] += 1\n",
        "            else:\n",
        "                token_dct[token] = 0\n",
        "\n",
        "    id2token = ['<pad>', '<unk>'] + sorted(token_dct, key=token_dct.get, reverse=True)[:max_vocab_size]\n",
        "\n",
        "    count = 0\n",
        "    for token in id2token:\n",
        "        index_dct[token] = count\n",
        "        count += 1\n",
        "\n",
        "\n",
        "\n",
        "    pkl.dump(id2token, open(\"id2token.p\", \"wb\"))\n",
        "    pkl.dump(index_dct, open(\"token2id.p\",\"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3Czos6w-Lga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token2id = pkl.load(open(\"token2id.p\", \"rb\"))\n",
        "id2token = pkl.load(open(\"id2token.p\", \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5eORL1o-S5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def token2index_dataset(tokens_data,token2id):\n",
        "    indices_data = []\n",
        "    for tokens in tokens_data:\n",
        "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
        "        indices_data.append(index_list)\n",
        "    return indices_data\n",
        "\n",
        "#creating and pickling fully tokenized data\n",
        "if not os.path.exists('tokenized_test_data.p'):\n",
        "    tokenized_train_data = []\n",
        "    for i in range(4):\n",
        "        print(i)\n",
        "        train_tokens = pkl.load(open(\"train_tokens_\" + str(i+1)+\".p\", \"rb\"))\n",
        "\n",
        "        tokenized_train_data += token2index_dataset(train_tokens, token2id)\n",
        "\n",
        "    print(len(tokenized_train_data))\n",
        "    pkl.dump(tokenized_train_data, open(\"tokenized_train_data.p\", \"wb\"))\n",
        "  \n",
        "    val_tokens = pkl.load(open(\"val_tokens.p\", \"rb\"))\n",
        "    tokenized_val_data = token2index_dataset(val_tokens, token2id)\n",
        "\n",
        "    test_tokens = pkl.load(open(\"test_tokens.p\", \"rb\"))\n",
        "    tokenized_test_data = token2index_dataset(test_tokens, token2id)\n",
        "\n",
        "    pkl.dump(tokenized_val_data, open(\"tokenized_val_data.p\", \"wb\"))\n",
        "    pkl.dump(tokenized_test_data, open(\"tokenized_test_data.p\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNKfOtr1Drlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#start \n",
        "\n",
        "tokenized_train_data = pkl.load(open(\"tokenized_train_data.p\", \"rb\"))\n",
        "tokenized_val_data = pkl.load(open(\"tokenized_val_data.p\", \"rb\"))\n",
        "tokenized_test_data = pkl.load(open(\"tokenized_test_data.p\", \"rb\"))\n",
        "\n",
        "#train_labels = 1*(np.array(train_df['gender']) == 'male')\n",
        "#val_labels = 1*(np.array(val_df['gender']) == 'male')\n",
        "#test_labels = 1*(np.array(test_df['gender']) == 'male')\n",
        "\n",
        "#age labels\n",
        "train_labels = np.array(train_df['label']) - 1\n",
        "val_labels = np.array(val_df['label']) - 1\n",
        "test_labels = np.array(test_df['label']) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T0fV_tADs0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SENTENCE_LENGTH = 250\n",
        "class BlogDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
        "    Note that this class inherits torch.utils.data.Dataset\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, data_list, target_list,):\n",
        "        \"\"\"\n",
        "        @param data_list: list of newsgroup tokens \n",
        "        @param target_list: list of newsgroup targets \n",
        "\n",
        "        \"\"\"\n",
        "        self.data_list = data_list\n",
        "        self.target_list = target_list\n",
        "        assert (len(self.data_list) == len(self.target_list))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "        \n",
        "    def __getitem__(self, key):\n",
        "        \"\"\"\n",
        "        Triggered when you call dataset[i]\n",
        "        \"\"\"\n",
        "        \n",
        "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
        "        label = self.target_list[key]\n",
        "        return [token_idx, len(token_idx), label]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u4AZkd9DxsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = BlogDataset(tokenized_train_data, train_labels)\n",
        "val_dataset = BlogDataset(tokenized_val_data, val_labels)\n",
        "test_dataset = BlogDataset(tokenized_test_data, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LlyqMKGD189",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def blog_collate_func(batch):\n",
        "    \"\"\"\n",
        "    Customized function for DataLoader that dynamically pads the batch so that all \n",
        "    data have the same length\n",
        "    \"\"\"\n",
        "    data_list = []\n",
        "    label_list = []\n",
        "    length_list = []\n",
        "    #print(\"collate batch: \", batch[0][0])\n",
        "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
        "    for datum in batch:\n",
        "        label_list.append(datum[2])\n",
        "        length_list.append(datum[1])\n",
        "    # padding\n",
        "    for datum in batch:\n",
        "        padded_vec = np.pad(np.array(datum[0]), \n",
        "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
        "                                mode=\"constant\", constant_values=0)\n",
        "        data_list.append(padded_vec)\n",
        "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iylzqz1ED6zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=blog_collate_func,\n",
        "                                           shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=blog_collate_func,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=blog_collate_func,\n",
        "                                           shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHLcNN1EEKQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BagOfWords(nn.Module):\n",
        "    \"\"\"\n",
        "    BagOfWords classification model\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, hidden_dim2, num_classes):\n",
        "      \n",
        "        super(BagOfWords, self).__init__()\n",
        "        # pay attention to padding_idx \n",
        "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.linear1 = nn.Linear(emb_dim, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, hidden_dim2)\n",
        "        self.linear3 = nn.Linear(hidden_dim2, num_classes)\n",
        "    \n",
        "    def forward(self, data, length):\n",
        "  \n",
        "        out = self.embed(data)\n",
        "        out = torch.sum(out, dim=1)\n",
        "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
        "     \n",
        "        # return logits\n",
        "        out = F.relu(self.linear1(out.float()))\n",
        "        out = F.relu(self.linear2(out))\n",
        "        out = self.linear3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbUXMgoWEOBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "\n",
        "emb_dim = 300\n",
        "hidden_dim = 100\n",
        "hidden_dim2 = 64\n",
        "num_classes = 3\n",
        "model = BagOfWords(len(id2token), emb_dim, hidden_dim, hidden_dim2, num_classes)\n",
        "model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()  \n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13IcPYKFEZCu",
        "colab_type": "code",
        "outputId": "090e721d-cd96-4e7a-e35f-3f7989d5af7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "num_epochs = 3 # number epoch to train\n",
        "\n",
        "train_loss_history = []\n",
        "val_accuracy_history = []\n",
        "best_val_accuracy = 0\n",
        "n_no_improve = 0\n",
        "early_stop_patience=2\n",
        "\n",
        "# Function for testing the model\n",
        "def test_model(loader, model):\n",
        "    \"\"\"\n",
        "    Help function that tests the model's performance on a dataset\n",
        "    @param: loader - data loader for the dataset to test against\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    for data, lengths, labels in loader:\n",
        "        data_batch, length_batch, label_batch = data.to(device), lengths.to(device), labels\n",
        "\n",
        "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
        "        predicted = outputs.max(1, keepdim=True)[1]\n",
        "        predicted = predicted.cpu().detach()\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
        "    return (100 * correct / total)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
        "        model.train()\n",
        "        data_batch, length_batch, label_batch = data.to(device), lengths.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data_batch, length_batch)\n",
        "        loss = criterion(outputs, label_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # validate every 100 iterations\n",
        "\n",
        "        \n",
        "        if i > 0 and i % 1000 == 0:\n",
        "            # validate\n",
        "            val_accuracy = test_model(val_loader, model)\n",
        "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
        "                       epoch+1, num_epochs, i+1, len(train_loader), val_accuracy))\n",
        "            val_accuracy_history.append(val_accuracy)\n",
        "            if epoch>2:\n",
        "              if val_accuracy_history[-1]<=val_accuracy_history[-2] and val_accuracy_history[-2]<=val_accuracy_history[-3]:\n",
        "                break\n",
        "              elif val_accuracy_history[-1]>val_accuracy_history[-2]:\n",
        "                torch.save(model, 'best_model.pt')\n",
        "print(\"Best validation accuracy is: \", max(val_accuracy_history))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1/3], Step: [1001/3707], Validation Acc: 63.51518847879122\n",
            "Epoch: [1/3], Step: [2001/3707], Validation Acc: 65.54654914613992\n",
            "Epoch: [1/3], Step: [3001/3707], Validation Acc: 65.7914928779413\n",
            "Epoch: [2/3], Step: [1001/3707], Validation Acc: 67.36050995514283\n",
            "Epoch: [2/3], Step: [2001/3707], Validation Acc: 67.42248367041788\n",
            "Epoch: [2/3], Step: [3001/3707], Validation Acc: 68.01467694971275\n",
            "Epoch: [3/3], Step: [1001/3707], Validation Acc: 67.97827968836074\n",
            "Epoch: [3/3], Step: [2001/3707], Validation Acc: 68.50259699378296\n",
            "Epoch: [3/3], Step: [3001/3707], Validation Acc: 68.56948925788936\n",
            "Best validation accuracy is:  68.56948925788936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_2Mcp5cGcDn",
        "colab_type": "code",
        "outputId": "28430f0b-67b5-415c-ecc7-cf6ecbebd8c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def read_sentence(tokenized_sent):\n",
        "      sentence = ''\n",
        "      for idx in tokenized_sent:\n",
        "            sentence += ' '\n",
        "            sentence += id2token[idx]\n",
        "      \n",
        "      return sentence[1:]\n",
        "\n",
        "model.eval()\n",
        "for i, (data, lengths, labels) in enumerate(test_loader):\n",
        "      if i < 100:\n",
        "            data = data.to(device)\n",
        "            lengths = lengths.to(device)\n",
        "            outputs = model(data, lengths)\n",
        "            predicted = outputs.max(1, keepdim=True)[1]\n",
        "            predicted = predicted.cpu().detach()\n",
        "            if int(predicted[0]) == 1:\n",
        "                  \n",
        "            if predicted[0] != labels[0]:\n",
        "                  print('############################################################')\n",
        "                  print('actual:', labels[0] )\n",
        "                  print('predicted:', predicted[0])\n",
        "                  print(read_sentence(data[0]))\n",
        "                  print('############################################################')\n",
        "\n",
        "      else:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "                  laura says this is rosie talking to wheaton and laura we are bored rosie <unk> she says no i am rosie wheaton says we should eat <unk> beans rosie says how do you spell <unk> and that is that               <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(0)\n",
            "predicted: tensor([1])\n",
            "            this is just a test please remain calm i repeat this is just a test          <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "                  this is just to say that i know i 've been really horrible to everyone lately and i am very sorry ... it 's nothing personal i 've just been in a very bad mood ... i probably will continue to be in a very bad mood sometimes and if i bite you for talking to me i 'm not really mad at you i just do n't want to talk ... sorry ... oh and <unk> wonderful job last night <unk> pretty music <unk> aka the <unk>              <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "                  <unk> i 'm not putting these clothes back on unless they make me   <unk> yes yes all gone <unk> heh heh   <unk> what <unk> the dress   <unk> <unk> <unk> well skirt and shirt <unk> and little belt thing   <unk> <unk> <unk> pants <unk> it 's a <unk>   <unk> <unk> <unk> shakes head <unk> runs <unk> <unk>   <unk> aka <unk>              <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "              i used to cook for myself all the time making <unk> <unk> and even <unk>   now however i 'm getting pretty lazy   food is so good <unk> and cheap in the restaurants nevermind that <unk> love to go out to eat so if i did cook a large amount of food about half of it would go to waste anyways that i 've decided not to shop for anything more than noodles and booze   see photos for the result   far from what i expected i ended up losing weight and spending about the same amount of money go figure    urllink     what a balanced diet i have ... noodles and more noodles tuna <unk> <unk> sauce    urllink     my fridge the <unk> are just for show they 've been in there for like 6 weeks   notice the contents ketchup <unk> orange juice <unk> do beer <unk> <unk> <unk> onions          <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "              sometimes this place really makes me think   so many things are so different here language expressions people culture shopping driving habits but yet some things are just like home   take my building for instance there are a few guards we call them <unk> <unk> or mister in the lobby ... well they 're no so much guards as they are <unk> like at wal mart neat article   urllink here   after they figured i was not a visitor but a long term resident of seoul they started <unk> me waving and saying morning   huh morning   ok i guess they learned that greeting somewhere many <unk> in lower level jobs know absolutely no english and what they may have learned these old <unk> probably had long forgotten so i appreciated the effort   then i was <unk> skating <unk> to those of us who can pronounce it easily one lovely <unk> and another <unk> said morning   ok that 's two   interesting   then i got to thinking well it came to me while watching a <unk> ad that morning is everywhere in korea   this morning there i go again i saw a give away paper called <unk> korean <unk> of morning and then recalled the ad for   urllink <unk> 's sub <unk> car   a simple search on google korea came up with more an   urllink online bookstore an   urllink online <unk> a   urllink golf site   and\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "                  yeah ... i just wanted to tell you all i have updated my blog ^^   <unk>              <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "                  now that i have all of your <unk> ...   ... i have n't posted here in a long time in fact i think the only one who 's posted here in awhile is <unk> <unk> to <unk> <unk>   ah so ... school 's out <unk> summer is here <unk> i have nothing to do ... <unk> boring people need to call or im me and make times so i have something to do with people other then stay up till 2 and sleep till noon ... it gets very boring very quickly not to mention tiring    my typing 's go to hell today ... pay no mind to any <unk> <unk>   the <unk> 's in the water ... it was so gorgeous at the lake today we did n't have time to sail but the water was all <unk> and the wind was blowing hard across the lake and it was cold so i sat on the dock 's end and got <unk> on by waves and watched the golden sunset ... days like today are great it was so awesome to see crown point ruins <unk> in gold light ... and <unk> ... and water ... and dammit ... i wanted my camera <unk> it was at home ... :(   i 'm gon na leave now ... but i 'll be on for awhile    <unk> ta you lot <unk> the overly <unk>               <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(0)\n",
            "predicted: tensor([1])\n",
            "        <unk> by <unk> <unk>   do n’t stop do n’t apologize relax   i ’m here now tell me a story   <unk> <unk> between <unk> above   <unk> small patches of <unk> land   darkness <unk> and a small <unk> <unk>   <unk> <unk>   legs cycle impact no longer felt   flying without wings           <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "                  i am not perfect i m sorry when i hurt people but you are amazing you know how i feel   <unk>              <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "                  lately i ve been thinking <unk> and <unk> alot about dating and relationships and other things   i think some people want a perfect boyfriend girlfriend and since that does nt happen much the person tends to make someone they find they like a little perfect to them   so my question is would you personally make a person change their ways habits looks whatever to your version perfect person    the answer to my own question is no   i will accept the person for who they are that s why i fell in love with them anyway is nt it personally i m willing to accept a persons bad habits no matter how bad they might be   no one is perfect and as   urllink <unk>   said being perfect would be an <unk> i 'm assuming this posts comments will be more than alot of others and people do nt argue in the comments please thanks   i can already smell <unk> everyone   <unk> a.k.a the <unk> <unk> <unk> smash <unk> in <unk> car crash              <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "                  it is the most beautiful and wonderful thing but there is a dark side a side we do not see the side of when the love is gone the absence of it and the fear you have that one day you will have to endure that absence i fear i will not be strong enough i sit and realize that 18 hrs away is driving me mad as i sit here alone watching tv playing games reading making jewelry eating <unk> anything to keep me busy it is funny that in me a know that i do n't need nathan to the point that it is a bad thing but i also know the luxury of seeing the world in color instead of black and white and now when i go back to the mediocre past in which i once <unk> i am falling apart i sit alone here i ca n't turn to jessica who is in <unk> with justin i can not turn to my parents who are in arizona or my sister who is with them not even my other sister who is with her love in ohio the world is suddenly empty and my house so large and <unk> of course the dogs keep me company but it is n't the same i guess i should go out to stay busy and go shopping or go just join the world but the world is a scary place and instead i sit hear in hopes that\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "              there are a few ways to beat the heat here in seoul one is to simply stay at work but with the government imposed   urllink <unk> work week   coming into effect and since i ca n't really figure out why i 'd work 7 days a week that is n't a very <unk> option you could go to the beach but it tends to get a little crowded as   urllink this story   <unk> or you can go see movies if you do though as i noted in a   urllink past blog get ready for some comedy -- and i mean before the movie starts one of my favorite <unk> is the brand new <unk> in <unk> the staff there have some pretty wild costumes there is a <unk> 's restaurant on the top 2 floors too where apparently the food is n't so hot but there 's a magic show to <unk> the kids the <unk> 's staff even the guys have <unk> and <unk> <unk> on their uniforms and the female theatre staff have get this wings ya they 're dressed as angels see pics    urllink      angels complete with wings and <unk> ... the whole <unk>    they also all have this cute well hilarious is more appropriate little <unk> they do when they greet you and say good bye they put their left hand on their hip their right hand up as if they 're swearing on a bible and\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "              korea 's pretty funny sometimes   take a look at   urllink this article   about changing the age of majority from 20 already a year younger than the u.s. to 19 the same as british columbia canada but higher than the 18 that is <unk> <unk> and in some canadian <unk>   here parents are commenting on the ability to take on rights and responsibilities at the tender age of 19    my boy is almost an adult now and the law now even <unk> him a man but he has to learn his responsibilities and accept his own choices in life han ho sun mother of a <unk> old said but what does he know he is not ready to make decisions as an adult yet and if he is granted too much freedom i 'm worried he 'll get himself into trouble    other parents of young adults agreed they nodded their heads to the idea that the government before <unk> the adult age should provide training and programs to teach what adult responsibilities <unk> such as building up a good credit record making political decisions and getting married    what 19 years kids that age are n't really mature enough to handle anything let alone complete <unk>   said one parent who asked for <unk>    the first two seem pretty sensible but the last one if the name was n't <unk> would be prime <unk> for the   urllink tonight show 's headlines  \n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(0)\n",
            "predicted: tensor([1])\n",
            "              i am struggling with a decision that really should not be taking me this long he i am trying to decide whether or not to race this weekend and there are more argument for doing the race then there are against it but for some reason i seem <unk> maybe i should take that as a sign i do n't know argh   i was going to try and make my self make up my mind by the end of today but now i 'm going to give myself til the end of tomorrow i 'm such a <unk>   the exciting news is that i am an aunt my big brother 's wife had their kid he was born yesterday at <unk> <unk> 10 oz 21 inches long i am dying to see a picture of the brat i 'm going to have to call an bug my brother i wish with all of my heart that they were close enough for me to just take a day and drive down to see them but that is not going to happen it would take between 24 30 hours to get there so ... i'll have to wait til christmas to see the brat i 'm going to go shopping on sat for him so much fun having a nephew to spoil             <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "     urllink     <unk> is 10 years old and plays a mean iraqi <unk>   the trouble is all the songs he knows are sad   i tried to show him some happy tunes with my <unk> <unk>   zen <unk>   <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "    <unk> about as traditional as it gets     in case you do n't have it <unk> urllink <unk> flash 7        <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(0)\n",
            "predicted: tensor([1])\n",
            "                  met <unk> this morning then we went to <unk> to get help from raymond maths .. no choice la .. cos there 's a maths quiz coming up and our <unk> is damn boring seriously yesterday was the very first time i really can listen and pay attention during maths with minimal distraction   went to <unk> in the afternoon with <unk> and mandy .. <unk> in the library till it close .. badminton at 5 pm <unk> sports hall .. i only managed to do little stuff at <unk> cos i ca n't study outside .. many pple plus <unk> .. so irritating   headed for <unk> after that .. went <unk> to buy fruits and bars then <unk> did n't allow me to go home so accompanied her to <unk> .. she wanna buy a new guitar rich girl        <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "    <unk> this is on one of the <unk> 's cds   sharon <unk> plays it a lot better than i do duh a <unk> in the key of g. i 'm working on the <unk> brittany <unk> tribute <unk> hurry to the <unk> :)       <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "     urllink     well now i had to get myself a new bow for my three <unk> so what better bow to get than the <unk>   i 'll let you know how it works out ... <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "         online communities versus offline communities    ah yes the vampire community in the early days there was no internet or it was so expensive that it was limited <unk>   but nowadays with the fast cheap internet the vampire community has infected it with their activities   yet there are some things you ca n't have in online communities it does n't fills the need for us to meet face to face to talk to eachother for instance by phone    it might look that we get closer over the internet but .. there is a limit in how close we can get    and on certain times and moments you <unk> need to think about crossing the <unk> and meet face to face    and yes then we can get into a shock .. our inner being can be very different from our outer shell and also people can <unk> being nice while being assholes who wish to abuse you   such are the <unk> yet this weakness touches every area where the online meets the offline   the internet in the end is <unk> a tool to connect things ... and in humanity the final cause is to communicate      <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "              love is the strangest thing in this world   grown men that can take a two by four to the face and not <unk> would run from love   guys who have it all together and never seem to cry ball like a baby because of love   someone who is in the depths of despair and <unk> like they will never work their way back up seem to suddenly <unk> at the notion of love   we were put on this earth due to one reason   love   we were made in god 's image everything that we are god is and more   the only emotion i can think of that would lead a person to all kinds of actions   a brother who loves his sister may beat up a bully or gently warn a potential boyfriend   a husband can love his wife so much that he would cry just watching her sleep   my experiences with love have mostly been on the lighter side of things ... mostly friendships   but some friendships can become as emotionally <unk> as other relationships ... sometimes even more so   i thankfully have at least been blessed to have an amazing friendship with at least one person   i feel sorry for anyone who does n't have at least that one friend   i believe that life would be a lot harder on me if it was n't for that one person   that one friend\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "        the well meaning drunk oh sure their heart 's in the right place and i 'm glad he stopped by to <unk> for all the noise and such but at half four in the morning there are better things i can think of doing and i know he was drunk but his admission that they 'd been a bit hard on me was both pleasant and unexpected   late night becomes early morning and television becomes something else entirely apparently doctor richard <unk> is still on the run and is these days looking like a poor man 's gary <unk> this week he escaped by going out a window genius   on the subject of <unk> television friday 's episode of charlie 's angels had one of them go <unk> at a women 's prison initially set upon by the top dog so to speak she later <unk> a friend by <unk> a drowning woman from the swimming pool and goes on to meet her contact in the massage <unk> this a   prison yes swimming <unk> and massage <unk> that 's more facilities than a lot of hotels and well <unk>    quote of the day is me on possible pick up lines whilst <unk> the toaster i like my toast like i like my women white thick and <unk> ...    and a hello to sarah our <unk> <unk> who will surely be the best we have ever had her arrangement of my <unk> fridge <unk> was\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(0)\n",
            "predicted: tensor([1])\n",
            "        life is n't a journey to the grave with the intentions of arriving safely in a pretty well <unk> body but rather to <unk> in <unk> thoroughly used up totally worn out loudly <unk> damn what a ride            <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(0)\n",
            "predicted: tensor([1])\n",
            "           i never put wet towels on the floor any more       so i am sitting in journalism bored out of my mind mrs. <unk> is doing ap test so <unk> is here watching us .... let see how many people are working in this room no one seriously one girl is sleeping on two chairs chris is <unk> a picture of a baby in photoshop there s four people in the corner laughing over something in the corner there s like 6 people on the floor talking about prom and that s about it so bored and he wo nt let us leave the room i hate school hate it ....   i am going to go because this is nt <unk> my <unk>             <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n",
            "############################################################\n",
            "actual: tensor(1)\n",
            "predicted: tensor([0])\n",
            "        <unk> love dawn of the sun is the end of night the end of summer is the <unk> of winter   so many times when you love someone even loving was painful when the love was broken so much does the <unk> of love hurt the heart   the birth of love is the dawn of joy and the end of love   is the <unk> of pain            <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "############################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRCcCtcSjEPR",
        "colab_type": "code",
        "outputId": "00f66285-625c-4850-a7bf-a88fb05ec589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "#@title Download GloVe word embeddings\n",
        "\n",
        "# === Download GloVe word embeddings\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "# === Unzip word embeddings and use only the top 50000 word embeddings for speed\n",
        "# !unzip glove.6B.zip\n",
        "# !head -n 50000 glove.6B.300d.txt > glove.6B.300d__50k.txt\n",
        "\n",
        "# === Download Preprocessed version\n",
        "!wget https://docs.google.com/uc?id=1KMJTagaVD9hFHXFTPtNk0u2JjvNlyCAu -O glove_split.aa\n",
        "!wget https://docs.google.com/uc?id=1LF2yD2jToXriyD-lsYA5hj03f7J3ZKaY -O glove_split.ab\n",
        "!wget https://docs.google.com/uc?id=1N1xnxkRyM5Gar7sv4d41alyTL92Iip3f -O glove_split.ac\n",
        "!cat glove_split.?? > 'glove.6B.300d__50k.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-15 12:40:59--  https://docs.google.com/uc?id=1KMJTagaVD9hFHXFTPtNk0u2JjvNlyCAu\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.202.139, 173.194.202.100, 173.194.202.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.202.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘glove_split.aa’\n",
            "\n",
            "glove_split.aa          [ <=>                ]   3.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-15 12:41:30 (9.22 MB/s) - ‘glove_split.aa’ saved [3228]\n",
            "\n",
            "--2020-05-15 12:41:32--  https://docs.google.com/uc?id=1LF2yD2jToXriyD-lsYA5hj03f7J3ZKaY\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.20.138, 74.125.20.113, 74.125.20.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.20.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘glove_split.ab’\n",
            "\n",
            "glove_split.ab          [ <=>                ]   3.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-15 12:42:03 (9.12 MB/s) - ‘glove_split.ab’ saved [3228]\n",
            "\n",
            "--2020-05-15 12:42:04--  https://docs.google.com/uc?id=1N1xnxkRyM5Gar7sv4d41alyTL92Iip3f\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.195.138, 74.125.195.102, 74.125.195.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.195.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/q69afpo502fkh1mlf0p1j5nisn32soha/1589546475000/14514704803973256873/*/1N1xnxkRyM5Gar7sv4d41alyTL92Iip3f [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-15 12:42:06--  https://doc-04-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/q69afpo502fkh1mlf0p1j5nisn32soha/1589546475000/14514704803973256873/*/1N1xnxkRyM5Gar7sv4d41alyTL92Iip3f\n",
            "Resolving doc-04-0g-docs.googleusercontent.com (doc-04-0g-docs.googleusercontent.com)... 74.125.195.132, 2607:f8b0:400e:c09::84\n",
            "Connecting to doc-04-0g-docs.googleusercontent.com (doc-04-0g-docs.googleusercontent.com)|74.125.195.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘glove_split.ac’\n",
            "\n",
            "glove_split.ac          [  <=>               ]  23.49M  69.0MB/s    in 0.3s    \n",
            "\n",
            "2020-05-15 12:42:07 (69.0 MB/s) - ‘glove_split.ac’ saved [24629432]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AfN4rYTOmCD",
        "colab_type": "text"
      },
      "source": [
        "## Load GloVe Embeddings\n",
        "\n",
        "We are going to reuse the code from Lab 2 here. In addition, we will add a padding token and an unknown token to our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSF0C4jHjnSz",
        "colab_type": "code",
        "outputId": "73638dc8-9599-443a-d382-2fee1099907b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "def load_glove(glove_path, embedding_dim):\n",
        "    with open(glove_path) as f:\n",
        "        token_ls = [PAD_TOKEN, UNK_TOKEN]\n",
        "        embedding_ls = [np.zeros(embedding_dim), np.random.rand(embedding_dim)]\n",
        "        for line in f:\n",
        "            token, raw_embedding = line.split(maxsplit=1)\n",
        "            token_ls.append(token)\n",
        "            embedding = np.array([float(x) for x in raw_embedding.split()])\n",
        "            embedding_ls.append(embedding)\n",
        "        embeddings = np.array(embedding_ls)\n",
        "    return token_ls, embeddings\n",
        "\n",
        "PAD_TOKEN = '<PAD>'\n",
        "UNK_TOKEN = '<UNK>'\n",
        "EMBEDDING_DIM=300 # dimension of Glove embeddings\n",
        "glove_path = \"glove.6B.300d__50k.txt\"\n",
        "vocab, embeddings = load_glove(glove_path, EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-212d38a7a1b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m \u001b[0;31m# dimension of Glove embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mglove_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"glove.6B.300d__50k.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_glove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-212d38a7a1b4>\u001b[0m in \u001b[0;36mload_glove\u001b[0;34m(glove_path, embedding_dim)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxsplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtoken_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0membedding_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_ls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-212d38a7a1b4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxsplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtoken_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0membedding_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_ls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'html><html><head><title>Google'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IDg2lbn1Cur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTMClassifier classification model\n",
        "    \"\"\"\n",
        "    def __init__(self, emb_dim,hidden_size, num_layers, num_classes, bidirectional, vocab_size = 10000, dropout_prob=0.3):\n",
        "        super().__init__()\n",
        "        #self.embedding_layer = self.load_pretrained_embeddings(embeddings)\n",
        "        self.embedding_layer = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.dropout = dropout_prob\n",
        "        self.lstm = nn.LSTM(input_size=emb_dim, hidden_size=hidden_size, num_layers = num_layers, dropout = self.dropout, bidirectional = bidirectional)\n",
        "        self.non_linearity = F.relu # For example, ReLU\n",
        "        if bidirectional:\n",
        "          self.clf = nn.Linear(hidden_size*2, num_classes) # classifier layer\n",
        "        else:\n",
        "          self.clf = nn.Linear(hidden_size, num_classes)\n",
        "        \"\"\"\n",
        "           define the components of your BiLSTM Classifier model\n",
        "           You may refer to Lab2 for reference\n",
        "           2. TODO: Your code here\n",
        "        \"\"\"\n",
        "    \n",
        "    def load_pretrained_embeddings(self, embeddings):\n",
        "        \"\"\"\n",
        "           The code for loading embeddings from Lab 2\n",
        "           Unlike lab, we are not setting `embedding_layer.weight.requires_grad = False`\n",
        "           because we want to finetune the embeddings on our data\n",
        "        \"\"\"\n",
        "        embedding_layer = nn.Embedding(embeddings.shape[0], embeddings.shape[1], padding_idx=0)\n",
        "        embedding_layer.weight.data = torch.Tensor(embeddings).float()\n",
        "        return embedding_layer\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeddings = self.embedding_layer(inputs)\n",
        "        #embeddings = self.lookup(inputs)\n",
        "        lstm_outputs = self.lstm(embeddings)[0]\n",
        "        out = torch.max(lstm_outputs, dim=1)[0]\n",
        "        out = self.non_linearity(out)\n",
        "        logits = self.clf(out)\n",
        "        \"\"\"\n",
        "           Write forward pass for LSTM\n",
        "           Example, forward:= embedding -> bilstm -> pooling (sum?mean?max?) \n",
        "                              nonlinearity -> classifier\n",
        "           Refer to: https://arxiv.org/abs/1705.02364 \n",
        "           Return logits\n",
        "           You may refer to Lab2 for embedding lookup and how to return logits\n",
        "           3. TODO: Your code here\n",
        "        \"\"\"\n",
        "        \n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaPW_CjlK0F7",
        "colab_type": "code",
        "outputId": "7c5d0981-f4ad-42f4-c201-623633359dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def test_model(loader, model):\n",
        "    \"\"\"\n",
        "    Help function that tests the model's performance on a dataset\n",
        "    @param: loader - data loader for the dataset to test against\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    for data, lengths, labels in loader:\n",
        "        data_batch, length_batch, label_batch = data.to(device), lengths.to(device), labels\n",
        "\n",
        "        outputs = F.softmax(model(data_batch), dim=1)\n",
        "        predicted = outputs.max(1, keepdim=True)[1]\n",
        "        predicted = predicted.cpu().detach()\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
        "    return (100 * correct / total)\n",
        "\n",
        "# BiLSTM hyperparameters\n",
        "hidden_size = 64\n",
        "num_layers = 1\n",
        "#num_classes = 2\n",
        "num_classes = 3\n",
        "bidirectional=True\n",
        "torch.manual_seed(1234)\n",
        "emb_dim = 300\n",
        "\n",
        "# if cuda exists, use cuda, else run on cpu\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "\n",
        "model = LSTMClassifier(emb_dim, hidden_size, num_layers, num_classes, bidirectional, dropout_prob=.01)\n",
        "model.to(device)\n",
        "#model.load_state_dict(torch.load('best_model_gender.pt'))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.01 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOlop_TMOD9V",
        "colab_type": "code",
        "outputId": "f1e64c24-eb6f-4a4a-8fb2-acaabff9b89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "train_loss_history = []\n",
        "val_accuracy_history = []\n",
        "best_val_accuracy = 0\n",
        "n_no_improve = 0\n",
        "early_stop_patience=2\n",
        "NUM_EPOCHS=3\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
        "\n",
        "        model.train()\n",
        "        data_batch, length_batch, label_batch = data.to(device), lengths.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data_batch)\n",
        "        loss = criterion(outputs, label_batch)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if i > 0 and i % 1000 == 0:\n",
        "            # validate\n",
        "            val_accuracy = test_model(val_loader, model)\n",
        "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
        "                       epoch+1, num_epochs, i+1, len(train_loader), val_accuracy))\n",
        "            val_accuracy_history.append(val_accuracy)\n",
        "            if epoch>2:\n",
        "              if val_accuracy_history[-1]<=val_accuracy_history[-2] and val_accuracy_history[-2]<=val_accuracy_history[-3]:\n",
        "                break\n",
        "              elif val_accuracy_history[-1]>val_accuracy_history[-2]:\n",
        "                torch.save(model, 'best_model_gender.pt')\n",
        "print(\"Best validation accuracy is: \", max(val_accuracy_history))\n",
        "\n",
        "'''  \n",
        "for epoch in tqdm.notebook.tqdm(range(NUM_EPOCHS)):\n",
        "  model.train() \n",
        "  for i, (data_batch, data_length, batch_labels) in enumerate(train_loader):\n",
        "    preds = model(data_batch.to(device))\n",
        "    loss = criterion(preds, batch_labels.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    train_loss_history.append(loss.item())        \n",
        "    # The end of a training epoch  \n",
        "    accuracy = evaluate(model,test_loader,device)\n",
        "    val_accuracy_history.append(accuracy)\n",
        "    if accuracy > best_val_accuracy:\n",
        "      best_val_accuracy = accuracy\n",
        "      torch.save(model, 'best_model.pt')\n",
        "    else:\n",
        "      n_no_improve += 1\n",
        "      print(\"epoch: \",n_no_improve, accuracy)\n",
        "      if n_no_improve > early_stop_patience:\n",
        "        print(\"Early stopping at:\", n_no_improve)\n",
        "        break  \n",
        "print(\"Best Validation Accuracy: \", best_val_accuracy)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1/3], Step: [1001/3707], Validation Acc: 62.291453529550644\n",
            "Epoch: [1/3], Step: [2001/3707], Validation Acc: 64.17427402219249\n",
            "Epoch: [1/3], Step: [3001/3707], Validation Acc: 64.82057133863225\n",
            "Epoch: [2/3], Step: [1001/3707], Validation Acc: 65.73148658219878\n",
            "Epoch: [2/3], Step: [2001/3707], Validation Acc: 65.7344377114976\n",
            "Epoch: [2/3], Step: [3001/3707], Validation Acc: 65.87412449830802\n",
            "Epoch: [3/3], Step: [1001/3707], Validation Acc: 66.2056346895412\n",
            "Epoch: [3/3], Step: [2001/3707], Validation Acc: 66.38073502793736\n",
            "Epoch: [3/3], Step: [3001/3707], Validation Acc: 66.48894310222713\n",
            "Best validation accuracy is:  66.48894310222713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  \\nfor epoch in tqdm.notebook.tqdm(range(NUM_EPOCHS)):\\n  model.train() \\n  for i, (data_batch, data_length, batch_labels) in enumerate(train_loader):\\n    preds = model(data_batch.to(device))\\n    loss = criterion(preds, batch_labels.to(device))\\n    loss.backward()\\n    optimizer.step()\\n    optimizer.zero_grad()\\n    train_loss_history.append(loss.item())        \\n    # The end of a training epoch  \\n    accuracy = evaluate(model,test_loader,device)\\n    val_accuracy_history.append(accuracy)\\n    if accuracy > best_val_accuracy:\\n      best_val_accuracy = accuracy\\n      torch.save(model, \\'best_model.pt\\')\\n    else:\\n      n_no_improve += 1\\n      print(\"epoch: \",n_no_improve, accuracy)\\n      if n_no_improve > early_stop_patience:\\n        print(\"Early stopping at:\", n_no_improve)\\n        break  \\nprint(\"Best Validation Accuracy: \", best_val_accuracy)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyalZo6tSXo_",
        "colab_type": "code",
        "outputId": "1fca17be-1f00-4c62-c764-91864621fe7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "pd.Series(train_loss_history).plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e2e3ea748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt8iNjFwPVtc",
        "colab_type": "code",
        "outputId": "ff5823e9-aa34-4978-faa1-1b5ec89b3bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "pd.Series(val_accuracy_history).plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e26178358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSkdBx1ULCFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, dataloader, device):\n",
        "    accuracy = None\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        for batch_text, batch_length, batch_labels in dataloader:\n",
        "            batch_length = batch_length.to(device)\n",
        "            batch_text = batch_text.to(device)\n",
        "\n",
        "            #preds = model(batch_text, batch_length)\n",
        "            preds = model(batch_text)\n",
        "\n",
        "            all_preds.append(preds.detach().cpu().numpy())\n",
        "            all_labels.append(batch_labels)\n",
        "    predicted=np.concatenate(all_preds, axis=0)\n",
        "    label=np.concatenate(all_labels, axis=0)\n",
        "    accuracy=(np.array(label)==predicted.argmax(-1)).mean()\n",
        "    return accuracy \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw6KtE2uSf1X",
        "colab_type": "code",
        "outputId": "fd57ed0c-f3f0-4988-d5e1-1b81de3c2b57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Reload best model from saved checkpoint\n",
        "# Compute test accuracy\n",
        "#model = torch.load('best_model_gender.pt')\n",
        "#model.to(device)\n",
        "test_accuracy = evaluate(model, test_loader,device)\n",
        "print(test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6746148852033288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djo4UHWiXBbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_classes(model, dataloader, device):\n",
        "    correct0 = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    total0 = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_text, batch_length, batch_labels in dataloader:\n",
        "            batch_length = batch_length.to(device)\n",
        "            batch_text = batch_text.to(device)\n",
        "\n",
        "            #preds = model(batch_text, batch_length)\n",
        "            preds = F.softmax(model(batch_text)).argmax(-1)\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "\n",
        "            batch_labels = batch_labels.numpy()\n",
        "\n",
        "            for i in range(preds.shape[0]):\n",
        "                  lab = batch_labels[i]\n",
        "                  pred = preds[i]\n",
        "                  if lab == 0:\n",
        "                        total0 +=1\n",
        "                        if pred == 0:\n",
        "                              correct0 += 1\n",
        "                  elif lab == 1:\n",
        "                        total1 +=1\n",
        "                        if pred == 1:\n",
        "                              correct1 += 1\n",
        "                  else:\n",
        "                        total2 += 1\n",
        "                        if pred == 2:\n",
        "                              correct2 += 1\n",
        "    return correct0/total0, correct1/total1, correct2/total2 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chm3yxnwCZ_R",
        "colab_type": "code",
        "outputId": "7c12b991-fd38-46e4-b587-0457a2cedf0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "evaluate_classes(model, test_loader,device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.697050709593015, 0.7988610478359909, 0.254572417202175)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS4S-KmQCe1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}